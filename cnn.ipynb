{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYMqVvxUY99G"
   },
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "\n",
    "\n",
    "**Convolutional neural networks** imitate the structure of neurons that process images in the brain and use techniques to reduce neuron count, as well as maintaining positional relationships in the data.\n",
    "\n",
    "This is a convolutional network for the MNIST set of data to recognize handwritten digits, and then be able to see what works differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDMg3447a1a0"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n",
    "1. Run the cell below to import and prepare the MNIST data for your Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8666,
     "status": "ok",
     "timestamp": 1651254229074,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "a_m-ZiupMsB2",
    "outputId": "378e053f-602b-44e5-f833-b094b930c5f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 10:31:16.965016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 10:31:17.194676: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-10 10:31:17.194687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-10 10:31:17.221424: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 10:31:17.925747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-10 10:31:17.925795: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-10 10:31:17.925799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# helper functions\n",
    "def show_min_max(array, i):\n",
    "  random_image = array[i]\n",
    "  print(\"min and max value in image: \", random_image.min(), random_image.max())\n",
    "\n",
    "\n",
    "def plot_image(array, i, labels):\n",
    "  plt.imshow(np.squeeze(array[i]))\n",
    "  plt.title(\" Digit \" + str(labels[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28  \n",
    "\n",
    "num_classes = 10 \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "(train_images_backup, train_labels_backup), (test_images_backup, test_labels_backup) = mnist.load_data() \n",
    "\n",
    "print(train_images.shape) \n",
    "print(test_images.shape) \n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "train_images /= 255\n",
    "test_images /= 255\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "print(train_images[1232].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6NDRSEJZITd"
   },
   "source": [
    "## Creating Your Network\n",
    "\n",
    "Set up Epoch. \n",
    "\n",
    "Recommended: epoch = 10\n",
    "Model: Set to Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1651254229276,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "4m1pD9NPZQUs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 10:31:19.249705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-10 10:31:19.249897: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-10 10:31:19.249916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (francine-MS-7A38): /proc/driver/nvidia/version does not exist\n",
      "2022-10-10 10:31:19.250312: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "# Set your variables here: \n",
    "epochs =  10\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRBvYbyJiICv"
   },
   "source": [
    "## Adding Layers\n",
    "\n",
    "\n",
    "\n",
    "Adjust the number and size of filters in the layer â€” larger filters observe larger areas of the image at once, while smaller filters spot finer detail. A higher filter count will allow recognizing a wider range of features.\n",
    "\n",
    "There are multiple advantages to having filters that work this way:\n",
    "\n",
    "*  Small filters are more computationally efficient since they only examine a small portion of the image at once.\n",
    "\n",
    "*  Just like in real life, the filter can do a better job by focusing on a small simple problem and ignoring the distraction of the rest of the image.\n",
    "*  Because the filters are moved across the entire image, convolutional networks are good at identifying two images that have the same object but in different places in each image.\n",
    "\n",
    "\n",
    "### Implementing Convolutional Layers\n",
    "\n",
    "Keras provides functionality to easily create convolutional layers for your neural networks. Use Conv2D  to create the first convolutional layer of your network.\n",
    "\n",
    "1. In the cell below, fill in the following information: \n",
    "  * filters: 32\n",
    "  * kernal_size: (3, 3)\n",
    "  * activations: 'relu'\n",
    "  * input_shape: input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651254229276,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "a0V81DITiXko"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32, kernel_size=(3,3),activation='relu',input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjrIoNbeitaH"
   },
   "source": [
    "\n",
    "\n",
    "> The Conv2D class creates two-dimensional convolutional layers, meaning they scan across a flat surface, like an image.\n",
    "\n",
    "> There's also a Conv3D class, that scans across a three-dimensional volume.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQMLUrmpi4Uw"
   },
   "source": [
    "## Pooling Layers\n",
    "\n",
    "Processing images with convolutional layers can get computationally intense rather quickly. Successive layers of convolutions increase the number of neurons and computation time required.\n",
    "\n",
    "> Convolutional networks use **pooling layers** to manage that growth of complexity by simplifying and shrinking the data set.\n",
    "\n",
    "Pooling layers use a filter that moves across the data with a specified stride, simplifying the contents of each filter into a single value. This shrinks the size of the layer's output based on the filter's size.\n",
    "\n",
    "This also helps reduce the network's translation variance, which is how sensitive the network is to an object's exact position in an image.\n",
    "\n",
    "\n",
    "### Adding a Pooling Layer\n",
    "\n",
    "1. Set the pool size as (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651254229277,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "o22nw-1JjG3m"
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2aG8yXpjP4f"
   },
   "source": [
    "Convolutional Neural Networks often have more then one set of alternating Convolutional and Pooling Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8V2nnZIjJt_"
   },
   "source": [
    "## More Convolutional Layers\n",
    "\n",
    "By design, convolutional layers can examine the low-level features of an image.  By adding more convolutional layers the network can start to work with higher-level features.\n",
    "\n",
    "This layer is defined the same way as the last one, except for more filters, 64 here vs. 32 before.  Also, the input shape doesn't need to be defined, since it's inferred from the previous layer.\n",
    "\n",
    "1. In the cell below add another conv2d layer to the network, with `64` filters and a kernel size of `(3,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1651254229436,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "SajrPTEvjh6P"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4FP2YHnj_BX"
   },
   "source": [
    "## Dropout Layers\n",
    "\n",
    "A dropout layer takes a percentage of all the neurons in the input and deactivates them at random. This random dropout of neurons forces more of the network to adapt to the task.\n",
    "\n",
    "Without a dropout layer, larger networks run the risk of growing overdependent on a small set of competent neurons rather than the whole network learning the task. Becoming overdependent on certain neurons is called Overfitting and it can skew the output of your network. \n",
    "\n",
    "1. Set the rate of the dropout layer to `0.3` or 30%\n",
    "2. Run the cell to add this layer to your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651254229436,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "Evxp_hhGkXrs"
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(rate=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra_nVniXkbQn"
   },
   "source": [
    "3. Add another convolutional layer with `32` filters and a kernel size of `(3,3)` and an activation of `relu`. This will be the last calculation layer.\n",
    "4. Run the cell to add this layer to your network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651254229437,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "3BuJu8suknv2"
   },
   "outputs": [],
   "source": [
    "# Add your Conv2D layer here:\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoJtitmLkryn"
   },
   "source": [
    "## Dense and Flatten Layers\n",
    "\n",
    "At the end of the convolutional and pooling layers, you'll need to set up some neurons to help make your final classification decision. This will be a standard, fully connected layer of neurons. In order to connect these layers, you'll first need to flatten the 2D image's filters.\n",
    "\n",
    "Keras uses the  `Flatten`  function to create a flattening layer, and the  `Dense`  function to create dense layers.\n",
    "\n",
    "` units=32 ` is how big the output of the Dense layer will be, in this case, 32 neurons.\n",
    "\n",
    "1. Look at the cell below to see the Flatten() layer. \n",
    "2. Set the units (`32`) and activation `'relu'` for the Dense layer below.\n",
    "3. Run the cell to add these layers to your network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1651254229613,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "3y5ZRz8llE7W"
   },
   "outputs": [],
   "source": [
    "model.add(Flatten()) \n",
    "model.add(Dense(units=32 ,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-7n0_k1lT9O"
   },
   "source": [
    "## Output Layers\n",
    "Just like with your fully connected network, the final layer needs to shrink the previous layer down to just the number of possible classes. Like before, the decision is represented by the class with the highest weight. \n",
    "\n",
    "1. In the cell below, add a Dense layer with these stats: \n",
    "  * units: the number of output classes\n",
    "  * activation: 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651254229614,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "ivfdJjp0lvU0"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edkEWmTvlx0l"
   },
   "source": [
    "Finally, print out a summary of your network. \n",
    "\n",
    "2. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1651254229804,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "DS6Ej76el4nm",
    "outputId": "9a728f62-4cac-430e-9973-f54c4a85210e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 32)          18464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2592)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                82976     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,586\n",
      "Trainable params: 120,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-5ljYjvmArm"
   },
   "source": [
    "## Compiling the Network\n",
    "\n",
    "Just like with your first network, you are going to compile this network. The loss and metrics will be the same as your last network: `categorical_crossentropy`, and `accuracy`. This time, however, you are going to use a different training algorithm called **RMSProp**. \n",
    "\n",
    "RMSProp is one of several different training algorithms Keras defines to do the computation that actually teaches the network how to improve. For the neural network, the goal is to optimize the loss by making it as small as possible. RMSProp is one way the network can do this. \n",
    "\n",
    "1. Set each argument in the compile function below. \n",
    "  * loss: `'categorical_crossentropy'`\n",
    "  * optimizer: `'rmsprop'`\n",
    "  * metrics: `['accuracy']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651254229805,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "oHbJpcNPmXSf"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjt1pTcNmcEd"
   },
   "source": [
    "## Training\n",
    "\n",
    "The fit function does the actual work of running the training.  Now that the data has been processed and the model has been defined and compiled it is time to actually train the model on the data. In this network, you are going to use validation data to get an idea of how the network is performing with each epoch, instead of just once at the end. \n",
    "\n",
    "Let's look at the parameters of this function:\n",
    "\n",
    "Input: train_images\n",
    "Output: train labels\n",
    "\n",
    "batch_size = allows user to put the data into the networ in batches\n",
    "\n",
    "shuffle = True (shuffles option to true so each epoch is different and model is not relying on the order of the images)\n",
    "\n",
    "\n",
    "Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803278,
     "status": "ok",
     "timestamp": 1651255053404,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "G6dFaURCmlb9",
    "outputId": "9d77f4ca-6193-4f2e-90fa-c40216fd4302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 76s 80ms/step - loss: 0.1691 - accuracy: 0.9480 - val_loss: 0.0464 - val_accuracy: 0.9844\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.0367 - val_accuracy: 0.9863\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.0333 - val_accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 73s 78ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.0340 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 73s 78ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0311 - val_accuracy: 0.9899\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 74s 79ms/step - loss: 0.0210 - accuracy: 0.9938 - val_loss: 0.0264 - val_accuracy: 0.9910\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 75s 79ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0334 - val_accuracy: 0.9903\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 77s 82ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.0300 - val_accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0275 - val_accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 76s 81ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.0275 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd8d4790d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=64, epochs=epochs, validation_data=(test_images, test_labels), shuffle=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0NfFoionbKF"
   },
   "source": [
    "## Evaluating and Returning the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6764,
     "status": "ok",
     "timestamp": 1651255124196,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "izHrkleZ16e3",
    "outputId": "3ea762b0-cea0-457c-a778-dbcc6406c7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 0.0275 - accuracy: 0.9925 - 3s/epoch - 10ms/step\n",
      "Test accuracy: 0.9925000071525574\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "scores = model.evaluate(test_images, test_labels, verbose=0)\n",
    "# Add a print statement for the test accuracy\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdYa-yPfCVPb"
   },
   "source": [
    "## Saving your Model\n",
    "\n",
    "Like before, you might want to save a copy of this trained model to use later.\n",
    "\n",
    "1. Run this cell to save the model to your student folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1651255127642,
     "user": {
      "displayName": "Neha Bala",
      "userId": "08158616502322850116"
     },
     "user_tz": 420
    },
    "id": "Q4zIcoCTG2dz"
   },
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Walkthrough_ConvolutionalNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
